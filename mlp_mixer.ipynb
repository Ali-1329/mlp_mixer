{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-iRpJJ0vTECJ",
        "outputId": "fec83319-c02d-4f91-a5f7-1ffed333dec5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Sep  5 10:57:50 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   44C    P8    10W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### imports"
      ],
      "metadata": {
        "id": "OYsYRNjZCS25"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import (\n",
        "    Add,\n",
        "    Dense,\n",
        "    Conv2D,\n",
        "    GlobalAveragePooling1D,\n",
        "    Layer,\n",
        "    LayerNormalization,\n",
        "    Permute,\n",
        "    Softmax,\n",
        "    Activation,\n",
        "    Dropout\n",
        ")\n",
        "from tensorflow.keras import callbacks\n",
        "from keras.models import Sequential\n",
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "ctalDujHCPox"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "NOACY10vCSBJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### MlpBlock"
      ],
      "metadata": {
        "id": "oRdpQfaEEuuA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MlpBlock(Layer):\n",
        "    \"\"\"\n",
        "    this Block consists of 2 Linear Blocks, with Dropout, and Activation\n",
        "    \"\"\"    \n",
        "    def __init__(self, dim:int,\n",
        "     hidden_dim:int, \n",
        "     activation:Activation =keras.activations.gelu, \n",
        "     drop:float =0, \n",
        "     **kwargs\n",
        "    )->None:\n",
        "        \"\"\"\n",
        "        Constructs all necessary attributes for the MlpBlock object\n",
        "\n",
        "        Args:\n",
        "            dim (int): shows dimension of the output feature map \n",
        "            hidden_dim (int): represents the dimension of the bottleneck feature map\n",
        "            activation (Activation, optional): Activation function. Defaults to keras.activations.gelu.\n",
        "            drop (float, optional): if drop>0 means apply dropout with rate equals drop . Defaults to 0.\n",
        "        \"\"\"                \n",
        "        super(MlpBlock, self).__init__(**kwargs)\n",
        "        hidden_dim = hidden_dim or dim\n",
        "        self.mlp = Sequential([\n",
        "            Dense(hidden_dim), \n",
        "            Activation(activation), \n",
        "            Dropout(drop),\n",
        "            Dense(dim), \n",
        "            Dropout(drop)          \n",
        "        ])\n",
        "    \n",
        "    def call(self, inputs:tf.Tensor) ->tf.Tensor:\n",
        "        \"\"\"\n",
        "         calculates the output featuremap after applying MlpBlock\n",
        "\n",
        "        Args:\n",
        "            inputs (tf.Tensor): inputs of MlpBlock, that we want to apply 2 Linear layer sequentially to inputs\n",
        "\n",
        "        Returns:\n",
        "            tf.Tensor: output of the MlpBlock after applying 2 sequential Linear layers to the inputs\n",
        "        \"\"\"        \n",
        "        return self.mlp(inputs)\n",
        "        \n",
        "    def compute_output_shape(self, input_signature):\n",
        "        return (input_signature[0], self.dim)\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super(MlpBlock, self).get_config()\n",
        "        config.update({\n",
        "            'dim': self.dim,\n",
        "            'hidden_dim': self.hidden_dim\n",
        "        })\n",
        "        return config"
      ],
      "metadata": {
        "id": "sUIUpmpr-6mY"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### MixerBlock"
      ],
      "metadata": {
        "id": "ztY0OTfzEzlA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MixerBlock(Layer):\n",
        "    '''applies token_mixer module and channel_mixing module sequentially\n",
        "    '''\n",
        "    def __init__(\n",
        "        self, \n",
        "        num_patches:int, \n",
        "        channel_dim:int,\n",
        "        token_mixer_hidden_dim:int, \n",
        "        channel_mixer_hidden_dim:int = None, \n",
        "        activation:Activation = keras.activations.gelu, \n",
        "        **kwargs\n",
        "    )->None:\n",
        "        \"\"\"\n",
        "       Constructs all necessary variables fo MixerBlock\n",
        "\n",
        "        Args:\n",
        "            num_patches (int): shows number of patches in the input feature map\n",
        "            channel_dim (int): shows channels dimension in the input feature map\n",
        "            token_mixer_hidden_dim (int): dimension of the hidden layer in token_mixer module\n",
        "            channel_mixer_hidden_dim (int, optional): dimension of the hidden layer in channel_mixer module. Defaults to None.\n",
        "            activation (Activation, optional): activation function which is applied in MlpBlocks after first Linear layer. Defaults to keras.activations.gelu.\n",
        "        \"\"\"        \n",
        "        super(MixerBlock, self).__init__(**kwargs)\n",
        "        \n",
        "        self.num_patches = num_patches\n",
        "        self.channel_dim = channel_dim\n",
        "        self.token_mixer_hidden_dim = token_mixer_hidden_dim\n",
        "        self.activation = activation\n",
        "        self.channel_mixer_hidden_dim = channel_mixer_hidden_dim or self.token_mixer_hidden_dim\n",
        "\n",
        "        self.token_mixer = Sequential([\n",
        "            LayerNormalization(axis=1), \n",
        "            Permute((2, 1)), \n",
        "            MlpBlock(self.num_patches, self.token_mixer_hidden_dim), \n",
        "            Permute((2, 1)), \n",
        "        ])\n",
        "        self.channel_mixer = Sequential([\n",
        "            LayerNormalization(axis=1), \n",
        "            MlpBlock(self.channel_dim, channel_mixer_hidden_dim)\n",
        "        ])\n",
        "    def call(self, inputs:tf.Tensor) ->tf.Tensor:\n",
        "        \"\"\"\n",
        "        applies token_mixer module and channel_mixer module sequentially to the inputs and returns the output tensor\n",
        "\n",
        "        Args:\n",
        "            inputs (tf.Tensor): tensor which is given to the MixerBlock as an input\n",
        "\n",
        "        Returns:\n",
        "            tf.Tensor: output after applying the  token_mixer and the channel_mixer module\n",
        "        \"\"\"        \n",
        "        skip_x = inputs\n",
        "        token_mixer_output = self.token_mixer(inputs)\n",
        "\n",
        "        skip_x = skip_x + token_mixer_output\n",
        "        channel_mixer_output = self.channel_mixer(skip_x)\n",
        "\n",
        "        skip_x = skip_x + channel_mixer_output\n",
        "        channel_mixer_output = self.channel_mixer(skip_x)\n",
        "        x = skip_x + channel_mixer_output\n",
        "        return x\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return input_shape\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super(MixerBlock, self).get_config()\n",
        "        config.update({\n",
        "            'num_patches': self.num_patches,\n",
        "            'channel_dim': self.channel_dim,\n",
        "            'token_mixer_hidden_dim': self.token_mixer_hidden_dim,\n",
        "            'channel_mixer_hidden_dim': self.channel_mixer_hidden_dim,\n",
        "            'activation': self.activation,\n",
        "        })\n",
        "        return config"
      ],
      "metadata": {
        "id": "Mab-THQ_CmmN"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### MlpMixerBlock"
      ],
      "metadata": {
        "id": "b4k-QQJ4E3CK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def MlpMixerModel(\n",
        "        input_shape: int,\n",
        "        num_classes: int,\n",
        "        num_blocks: int,\n",
        "        patch_size: int,\n",
        "        hidden_dim: int,\n",
        "        tokens_mlp_dim: int,\n",
        "        channels_mlp_dim: int = None,\n",
        "        use_softmax: bool = False,\n",
        "):\n",
        "    height, width, _ = input_shape\n",
        "\n",
        "    if channels_mlp_dim is None:\n",
        "        channels_mlp_dim = tokens_mlp_dim\n",
        "\n",
        "    num_patches = (height*width)//(patch_size**2)  \n",
        "\n",
        "    inputs = keras.Input(input_shape)\n",
        "    x = inputs\n",
        "\n",
        "    x = Conv2D(hidden_dim,\n",
        "               kernel_size=patch_size,\n",
        "               strides=patch_size,\n",
        "               padding='same',\n",
        "               name='projector')(x)\n",
        "\n",
        "    x = keras.layers.Reshape([-1, hidden_dim])(x)\n",
        "\n",
        "    for _ in range(num_blocks):\n",
        "        x = MixerBlock(num_patches=num_patches,\n",
        "                       channel_dim=hidden_dim,\n",
        "                       token_mixer_hidden_dim=tokens_mlp_dim,\n",
        "                       channel_mixer_hidden_dim=channels_mlp_dim)(x)\n",
        "\n",
        "    x = GlobalAveragePooling1D()(x) \n",
        "\n",
        "    x = LayerNormalization(name='pre_head_layer_norm')(x)\n",
        "    x = Dense(num_classes, name='head')(x)\n",
        "\n",
        "    if use_softmax:\n",
        "        x = Softmax()(x)\n",
        "    return keras.Model(inputs, x)"
      ],
      "metadata": {
        "id": "Vru3DLvpCmih"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### callbacks"
      ],
      "metadata": {
        "id": "hRnetiB1FMVj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir files"
      ],
      "metadata": {
        "id": "pKW7qXcgFRUo"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = './files/model.h5'\n",
        "csv_path = \"./files/data.csv\""
      ],
      "metadata": {
        "id": "_xYbTgRxKj2Y"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_callbacks = [\n",
        "        callbacks.ModelCheckpoint(model_path),      # create_dir(files)\n",
        "        callbacks.CSVLogger(csv_path),\n",
        "        callbacks.TensorBoard(),\n",
        "        callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, min_lr=1e-6, verbose=1),\n",
        "        callbacks.EarlyStopping(monitor='val_loss', patience=50, restore_best_weights=False)\n",
        "    ]  "
      ],
      "metadata": {
        "id": "JZU3XL7iFOuY"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hyperparameters"
      ],
      "metadata": {
        "id": "FLgamb0tRSLr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size=16\n",
        "num_blocks=4\n",
        "patch_size=8\n",
        "hidden_dim=32\n",
        "tokens_mlp_dim=64\n",
        "channels_mlp_dim=128\n",
        "num_epochs = 300"
      ],
      "metadata": {
        "id": "356_8WN3RRvg"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training"
      ],
      "metadata": {
        "id": "sF_RZEMkFyzA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
        "x_train, x_val = x_train[:40000], x_train[40000:]\n",
        "y_train, y_val = y_train[:40000], y_train[40000:]\n",
        "model = MlpMixerModel(input_shape=x_train.shape[1:],\n",
        "                      num_classes=len(np.unique(y_train)), \n",
        "                      num_blocks=num_blocks, \n",
        "                      patch_size=patch_size,\n",
        "                      hidden_dim=hidden_dim, \n",
        "                      tokens_mlp_dim=tokens_mlp_dim,\n",
        "                      channels_mlp_dim=channels_mlp_dim,\n",
        "                      use_softmax=True)\n",
        "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy', metrics='acc')\n",
        "model.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=num_epochs, callbacks=[my_callbacks], batch_size=batch_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6wDuI0BT-ILf",
        "outputId": "26aea1ce-e709-483c-daec-0a5ab3e5133e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 2s 0us/step\n",
            "170508288/170498071 [==============================] - 2s 0us/step\n",
            "Epoch 1/300\n",
            "2500/2500 [==============================] - 49s 13ms/step - loss: 2.0051 - acc: 0.2575 - val_loss: 1.8061 - val_acc: 0.3376 - lr: 0.0010\n",
            "Epoch 2/300\n",
            "2500/2500 [==============================] - 30s 12ms/step - loss: 1.6987 - acc: 0.3860 - val_loss: 1.6441 - val_acc: 0.4045 - lr: 0.0010\n",
            "Epoch 3/300\n",
            "2500/2500 [==============================] - 30s 12ms/step - loss: 1.5704 - acc: 0.4387 - val_loss: 1.5221 - val_acc: 0.4590 - lr: 0.0010\n",
            "Epoch 4/300\n",
            "2500/2500 [==============================] - 31s 13ms/step - loss: 1.4800 - acc: 0.4732 - val_loss: 1.4845 - val_acc: 0.4705 - lr: 0.0010\n",
            "Epoch 5/300\n",
            "2500/2500 [==============================] - 30s 12ms/step - loss: 1.4185 - acc: 0.4947 - val_loss: 1.4188 - val_acc: 0.4955 - lr: 0.0010\n",
            "Epoch 6/300\n",
            "2500/2500 [==============================] - 31s 12ms/step - loss: 1.3707 - acc: 0.5107 - val_loss: 1.3838 - val_acc: 0.5116 - lr: 0.0010\n",
            "Epoch 7/300\n",
            "2500/2500 [==============================] - 30s 12ms/step - loss: 1.3337 - acc: 0.5261 - val_loss: 1.3716 - val_acc: 0.5143 - lr: 0.0010\n",
            "Epoch 8/300\n",
            "2500/2500 [==============================] - 31s 12ms/step - loss: 1.3006 - acc: 0.5364 - val_loss: 1.3593 - val_acc: 0.5208 - lr: 0.0010\n",
            "Epoch 9/300\n",
            "2500/2500 [==============================] - 31s 12ms/step - loss: 1.2735 - acc: 0.5469 - val_loss: 1.3505 - val_acc: 0.5229 - lr: 0.0010\n",
            "Epoch 10/300\n",
            "2500/2500 [==============================] - 30s 12ms/step - loss: 1.2465 - acc: 0.5550 - val_loss: 1.3210 - val_acc: 0.5290 - lr: 0.0010\n",
            "Epoch 11/300\n",
            "2500/2500 [==============================] - 30s 12ms/step - loss: 1.2247 - acc: 0.5637 - val_loss: 1.3159 - val_acc: 0.5399 - lr: 0.0010\n",
            "Epoch 12/300\n",
            "2500/2500 [==============================] - 30s 12ms/step - loss: 1.2010 - acc: 0.5709 - val_loss: 1.2937 - val_acc: 0.5440 - lr: 0.0010\n",
            "Epoch 13/300\n",
            "2500/2500 [==============================] - 30s 12ms/step - loss: 1.1815 - acc: 0.5819 - val_loss: 1.2905 - val_acc: 0.5470 - lr: 0.0010\n",
            "Epoch 14/300\n",
            "2500/2500 [==============================] - 31s 12ms/step - loss: 1.1643 - acc: 0.5859 - val_loss: 1.2946 - val_acc: 0.5466 - lr: 0.0010\n",
            "Epoch 15/300\n",
            "2500/2500 [==============================] - 31s 13ms/step - loss: 1.1487 - acc: 0.5895 - val_loss: 1.2899 - val_acc: 0.5437 - lr: 0.0010\n",
            "Epoch 16/300\n",
            "2500/2500 [==============================] - 30s 12ms/step - loss: 1.1322 - acc: 0.5963 - val_loss: 1.2989 - val_acc: 0.5431 - lr: 0.0010\n",
            "Epoch 17/300\n",
            "2500/2500 [==============================] - 30s 12ms/step - loss: 1.1159 - acc: 0.5999 - val_loss: 1.2806 - val_acc: 0.5550 - lr: 0.0010\n",
            "Epoch 18/300\n",
            "2500/2500 [==============================] - 31s 12ms/step - loss: 1.1014 - acc: 0.6066 - val_loss: 1.2800 - val_acc: 0.5562 - lr: 0.0010\n",
            "Epoch 19/300\n",
            "2500/2500 [==============================] - 30s 12ms/step - loss: 1.0870 - acc: 0.6122 - val_loss: 1.2856 - val_acc: 0.5490 - lr: 0.0010\n",
            "Epoch 20/300\n",
            "2500/2500 [==============================] - 31s 12ms/step - loss: 1.0732 - acc: 0.6175 - val_loss: 1.2775 - val_acc: 0.5552 - lr: 0.0010\n",
            "Epoch 21/300\n",
            "2500/2500 [==============================] - 31s 12ms/step - loss: 1.0602 - acc: 0.6187 - val_loss: 1.2611 - val_acc: 0.5592 - lr: 0.0010\n",
            "Epoch 22/300\n",
            "2500/2500 [==============================] - 30s 12ms/step - loss: 1.0487 - acc: 0.6245 - val_loss: 1.2852 - val_acc: 0.5517 - lr: 0.0010\n",
            "Epoch 23/300\n",
            "2500/2500 [==============================] - 31s 12ms/step - loss: 1.0371 - acc: 0.6271 - val_loss: 1.2635 - val_acc: 0.5607 - lr: 0.0010\n",
            "Epoch 24/300\n",
            "2500/2500 [==============================] - 30s 12ms/step - loss: 1.0228 - acc: 0.6337 - val_loss: 1.2985 - val_acc: 0.5540 - lr: 0.0010\n",
            "Epoch 25/300\n",
            "2500/2500 [==============================] - 30s 12ms/step - loss: 1.0084 - acc: 0.6387 - val_loss: 1.2917 - val_acc: 0.5552 - lr: 0.0010\n",
            "Epoch 26/300\n",
            "2497/2500 [============================>.] - ETA: 0s - loss: 0.9966 - acc: 0.6425\n",
            "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "2500/2500 [==============================] - 31s 12ms/step - loss: 0.9967 - acc: 0.6426 - val_loss: 1.2938 - val_acc: 0.5559 - lr: 0.0010\n",
            "Epoch 27/300\n",
            "2500/2500 [==============================] - 31s 12ms/step - loss: 0.9074 - acc: 0.6749 - val_loss: 1.2623 - val_acc: 0.5671 - lr: 1.0000e-04\n",
            "Epoch 28/300\n",
            "2500/2500 [==============================] - 31s 12ms/step - loss: 0.8943 - acc: 0.6818 - val_loss: 1.2655 - val_acc: 0.5669 - lr: 1.0000e-04\n",
            "Epoch 29/300\n",
            "2500/2500 [==============================] - 31s 12ms/step - loss: 0.8887 - acc: 0.6833 - val_loss: 1.2753 - val_acc: 0.5678 - lr: 1.0000e-04\n",
            "Epoch 30/300\n",
            "2500/2500 [==============================] - 31s 12ms/step - loss: 0.8850 - acc: 0.6859 - val_loss: 1.2796 - val_acc: 0.5668 - lr: 1.0000e-04\n",
            "Epoch 31/300\n",
            "2499/2500 [============================>.] - ETA: 0s - loss: 0.8811 - acc: 0.6873\n",
            "Epoch 31: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "2500/2500 [==============================] - 32s 13ms/step - loss: 0.8810 - acc: 0.6874 - val_loss: 1.2821 - val_acc: 0.5652 - lr: 1.0000e-04\n",
            "Epoch 32/300\n",
            "2500/2500 [==============================] - 32s 13ms/step - loss: 0.8689 - acc: 0.6913 - val_loss: 1.2813 - val_acc: 0.5664 - lr: 1.0000e-05\n",
            "Epoch 33/300\n",
            "2500/2500 [==============================] - 31s 12ms/step - loss: 0.8673 - acc: 0.6921 - val_loss: 1.2826 - val_acc: 0.5662 - lr: 1.0000e-05\n",
            "Epoch 34/300\n",
            "2500/2500 [==============================] - 31s 12ms/step - loss: 0.8668 - acc: 0.6914 - val_loss: 1.2826 - val_acc: 0.5663 - lr: 1.0000e-05\n",
            "Epoch 35/300\n",
            "2500/2500 [==============================] - 30s 12ms/step - loss: 0.8664 - acc: 0.6919 - val_loss: 1.2840 - val_acc: 0.5659 - lr: 1.0000e-05\n",
            "Epoch 36/300\n",
            "2496/2500 [============================>.] - ETA: 0s - loss: 0.8659 - acc: 0.6925\n",
            "Epoch 36: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
            "2500/2500 [==============================] - 31s 12ms/step - loss: 0.8659 - acc: 0.6924 - val_loss: 1.2850 - val_acc: 0.5658 - lr: 1.0000e-05\n",
            "Epoch 37/300\n",
            "2500/2500 [==============================] - 31s 12ms/step - loss: 0.8644 - acc: 0.6932 - val_loss: 1.2849 - val_acc: 0.5657 - lr: 1.0000e-06\n",
            "Epoch 38/300\n",
            "2500/2500 [==============================] - 30s 12ms/step - loss: 0.8643 - acc: 0.6933 - val_loss: 1.2849 - val_acc: 0.5660 - lr: 1.0000e-06\n",
            "Epoch 39/300\n",
            "2500/2500 [==============================] - 31s 12ms/step - loss: 0.8642 - acc: 0.6934 - val_loss: 1.2850 - val_acc: 0.5658 - lr: 1.0000e-06\n",
            "Epoch 40/300\n",
            "2500/2500 [==============================] - 30s 12ms/step - loss: 0.8642 - acc: 0.6934 - val_loss: 1.2851 - val_acc: 0.5656 - lr: 1.0000e-06\n",
            "Epoch 41/300\n",
            "2500/2500 [==============================] - ETA: 0s - loss: 0.8641 - acc: 0.6934\n",
            "Epoch 41: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
            "2500/2500 [==============================] - 31s 12ms/step - loss: 0.8641 - acc: 0.6934 - val_loss: 1.2851 - val_acc: 0.5658 - lr: 1.0000e-06\n",
            "Epoch 42/300\n",
            "2500/2500 [==============================] - 31s 12ms/step - loss: 0.8641 - acc: 0.6931 - val_loss: 1.2852 - val_acc: 0.5656 - lr: 1.0000e-06\n",
            "Epoch 43/300\n",
            "2500/2500 [==============================] - 31s 12ms/step - loss: 0.8641 - acc: 0.6933 - val_loss: 1.2853 - val_acc: 0.5655 - lr: 1.0000e-06\n",
            "Epoch 44/300\n",
            "2500/2500 [==============================] - 31s 12ms/step - loss: 0.8640 - acc: 0.6933 - val_loss: 1.2854 - val_acc: 0.5656 - lr: 1.0000e-06\n",
            "Epoch 45/300\n",
            "2500/2500 [==============================] - 30s 12ms/step - loss: 0.8640 - acc: 0.6932 - val_loss: 1.2854 - val_acc: 0.5656 - lr: 1.0000e-06\n",
            "Epoch 46/300\n",
            "2500/2500 [==============================] - 31s 12ms/step - loss: 0.8639 - acc: 0.6933 - val_loss: 1.2856 - val_acc: 0.5656 - lr: 1.0000e-06\n",
            "Epoch 47/300\n",
            "2500/2500 [==============================] - 31s 12ms/step - loss: 0.8639 - acc: 0.6933 - val_loss: 1.2856 - val_acc: 0.5657 - lr: 1.0000e-06\n",
            "Epoch 48/300\n",
            "2500/2500 [==============================] - 30s 12ms/step - loss: 0.8639 - acc: 0.6930 - val_loss: 1.2857 - val_acc: 0.5657 - lr: 1.0000e-06\n",
            "Epoch 49/300\n",
            "2500/2500 [==============================] - 31s 12ms/step - loss: 0.8638 - acc: 0.6933 - val_loss: 1.2858 - val_acc: 0.5656 - lr: 1.0000e-06\n",
            "Epoch 50/300\n",
            "2500/2500 [==============================] - 31s 12ms/step - loss: 0.8638 - acc: 0.6934 - val_loss: 1.2858 - val_acc: 0.5658 - lr: 1.0000e-06\n",
            "Epoch 51/300\n",
            "2500/2500 [==============================] - 31s 12ms/step - loss: 0.8638 - acc: 0.6932 - val_loss: 1.2859 - val_acc: 0.5655 - lr: 1.0000e-06\n",
            "Epoch 52/300\n",
            "2500/2500 [==============================] - 30s 12ms/step - loss: 0.8637 - acc: 0.6933 - val_loss: 1.2859 - val_acc: 0.5657 - lr: 1.0000e-06\n",
            "Epoch 53/300\n",
            "2500/2500 [==============================] - 31s 12ms/step - loss: 0.8637 - acc: 0.6933 - val_loss: 1.2860 - val_acc: 0.5657 - lr: 1.0000e-06\n",
            "Epoch 54/300\n",
            "2500/2500 [==============================] - 31s 12ms/step - loss: 0.8637 - acc: 0.6931 - val_loss: 1.2860 - val_acc: 0.5658 - lr: 1.0000e-06\n",
            "Epoch 55/300\n",
            "2500/2500 [==============================] - 31s 12ms/step - loss: 0.8636 - acc: 0.6933 - val_loss: 1.2861 - val_acc: 0.5661 - lr: 1.0000e-06\n",
            "Epoch 56/300\n",
            "2500/2500 [==============================] - 30s 12ms/step - loss: 0.8636 - acc: 0.6935 - val_loss: 1.2861 - val_acc: 0.5660 - lr: 1.0000e-06\n",
            "Epoch 57/300\n",
            "2500/2500 [==============================] - 31s 12ms/step - loss: 0.8635 - acc: 0.6935 - val_loss: 1.2862 - val_acc: 0.5664 - lr: 1.0000e-06\n",
            "Epoch 58/300\n",
            "2500/2500 [==============================] - 31s 12ms/step - loss: 0.8635 - acc: 0.6935 - val_loss: 1.2863 - val_acc: 0.5664 - lr: 1.0000e-06\n",
            "Epoch 59/300\n",
            "2500/2500 [==============================] - 31s 12ms/step - loss: 0.8635 - acc: 0.6932 - val_loss: 1.2864 - val_acc: 0.5663 - lr: 1.0000e-06\n",
            "Epoch 60/300\n",
            "2500/2500 [==============================] - 31s 12ms/step - loss: 0.8634 - acc: 0.6933 - val_loss: 1.2864 - val_acc: 0.5663 - lr: 1.0000e-06\n",
            "Epoch 61/300\n",
            "2500/2500 [==============================] - 30s 12ms/step - loss: 0.8634 - acc: 0.6934 - val_loss: 1.2865 - val_acc: 0.5664 - lr: 1.0000e-06\n",
            "Epoch 62/300\n",
            "2500/2500 [==============================] - 31s 12ms/step - loss: 0.8634 - acc: 0.6934 - val_loss: 1.2866 - val_acc: 0.5661 - lr: 1.0000e-06\n",
            "Epoch 63/300\n",
            "2500/2500 [==============================] - 30s 12ms/step - loss: 0.8633 - acc: 0.6932 - val_loss: 1.2867 - val_acc: 0.5662 - lr: 1.0000e-06\n",
            "Epoch 64/300\n",
            "2500/2500 [==============================] - 31s 13ms/step - loss: 0.8633 - acc: 0.6935 - val_loss: 1.2867 - val_acc: 0.5664 - lr: 1.0000e-06\n",
            "Epoch 65/300\n",
            "2500/2500 [==============================] - 32s 13ms/step - loss: 0.8633 - acc: 0.6935 - val_loss: 1.2868 - val_acc: 0.5663 - lr: 1.0000e-06\n",
            "Epoch 66/300\n",
            "2500/2500 [==============================] - 31s 13ms/step - loss: 0.8632 - acc: 0.6931 - val_loss: 1.2869 - val_acc: 0.5664 - lr: 1.0000e-06\n",
            "Epoch 67/300\n",
            "2500/2500 [==============================] - 31s 13ms/step - loss: 0.8632 - acc: 0.6933 - val_loss: 1.2870 - val_acc: 0.5666 - lr: 1.0000e-06\n",
            "Epoch 68/300\n",
            "2500/2500 [==============================] - 33s 13ms/step - loss: 0.8632 - acc: 0.6933 - val_loss: 1.2870 - val_acc: 0.5662 - lr: 1.0000e-06\n",
            "Epoch 69/300\n",
            "2500/2500 [==============================] - 32s 13ms/step - loss: 0.8631 - acc: 0.6935 - val_loss: 1.2871 - val_acc: 0.5662 - lr: 1.0000e-06\n",
            "Epoch 70/300\n",
            "2500/2500 [==============================] - 32s 13ms/step - loss: 0.8631 - acc: 0.6935 - val_loss: 1.2872 - val_acc: 0.5662 - lr: 1.0000e-06\n",
            "Epoch 71/300\n",
            "2500/2500 [==============================] - 31s 13ms/step - loss: 0.8631 - acc: 0.6934 - val_loss: 1.2872 - val_acc: 0.5663 - lr: 1.0000e-06\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f41703a5cd0>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ploting results"
      ],
      "metadata": {
        "id": "M792fjGoR0-w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_train_results():\n",
        "    '''plot the training results'''\n",
        "    csv = pd.read_csv(os.path.join(os.getcwd(), 'files/data.csv'))\n",
        "    plt.plot(csv['acc'], label='accuracy')\n",
        "    plt.plot(csv['val_acc'], label='validation accuracy')\n",
        "    plt.plot(csv['loss'], label='loss')\n",
        "    plt.plot(csv['val_loss'], label='validation loss')\n",
        "    plt.xlabel('epochs')\n",
        "    plt.ylabel('accuracy/loss')\n",
        "    plt.title('results of a simple mlp_mixer network on cifar10 dataset')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "plot_train_results()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "4WNL9SS0Rz10",
        "outputId": "3e53fd97-7a1c-41c1-9efd-ae08cb158209"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test"
      ],
      "metadata": {
        "id": "UUKilKq5S0mh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_model = tf.keras.models.load_model(model_path, custom_objects={'MixerBlock':MixerBlock})\n",
        "model.compile(optimizer = tf.keras.optimizers.RMSprop(learning_rate=1.0000e-06), loss='sparse_categorical_crossentropy', metrics='acc')\n",
        "loss, accuracy = model.evaluate(x_test, y_test, batch_size=batch_size)\n",
        "print('accuracy: ', accuracy)\n",
        "print('loss: ', loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SNoRdDbnGzsB",
        "outputId": "6179d776-4ec4-4355-cc10-69fbdd9c7f96"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "625/625 [==============================] - 4s 5ms/step - loss: 1.2938 - acc: 0.5693\n",
            "accuracy:  0.5692999958992004\n",
            "loss:  1.2937959432601929\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RAGiI5k-LK2V"
      },
      "execution_count": 33,
      "outputs": []
    }
  ]
}